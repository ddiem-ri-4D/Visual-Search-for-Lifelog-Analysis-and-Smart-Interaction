{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"visual_matching_with_deep_feature.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOPh8jFHlycJJdj3hm5nEuY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cNwuJ6kYKMlx"},"source":["#TUTORIAL: DEEP FEATURE BASED VISUAL SEARCH\n","This tutorial give a short implementation for the idea of using visual deep features for searching on a collection of images. The deep feature is deployed by using the last convolutional layer of VGG-16 pretrained model.This feature will be represented for an image and used for further seaching step. To compare two images, we comapre their representation vectors with some metrics such as distance and similarity."]},{"cell_type":"markdown","metadata":{"id":"aBRRJJrDLa-z"},"source":["# Step 1 - Preparation\n","This step setups a connection between the Colab server to the Google Drive server (authenticated by your Google account). By this way, you can synchronize the computational machine with your personal data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULRXv7xM3_TQ","executionInfo":{"status":"ok","timestamp":1623828835615,"user_tz":-420,"elapsed":366,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"118073fc-7564-42b5-f1f5-7db8bf5b4299"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvIOk7IJ4D6Y","executionInfo":{"status":"ok","timestamp":1623828842818,"user_tz":-420,"elapsed":370,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"84841836-3d4b-4980-d9ac-c507e7b10a0b"},"source":["# Check GDrive connection\n","# NOTE THAT: You should change this path based on your real configuration\n","tutorial_path = '/content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial/'\n","%cd '$tutorial_path'"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uoiHaxfp3uWl","executionInfo":{"status":"ok","timestamp":1623828845647,"user_tz":-420,"elapsed":376,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}}},"source":["from keras.preprocessing import image\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","import numpy as np\n","import glob"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZwGTziTmLgxi"},"source":["After connect to the drive, we continue to load pretrained VGG-16 model. You can replace VGG-16 by others new ones such as: Inception V3, ResNet-x, DenseNet-x,..."]},{"cell_type":"code","metadata":{"id":"qXFBBVZT34Ur","executionInfo":{"status":"ok","timestamp":1623828851567,"user_tz":-420,"elapsed":1241,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}}},"source":["# Load model\n","model = VGG16(weights='imagenet', include_top=False)\n","# Mô hình này đã được train trên tập dữ liệu\n","# Image Net với hàng triệu ảnh và hàng ngàn lớp đối tượng\n","#model.summary()"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCHDja_lL5LK"},"source":["#Step 2 - Extract deep feature\n","In this step, we use the pretrained VGG-16 model to extract the feature at the last convolutional layer. This feature contains high level feature with concepts."]},{"cell_type":"code","metadata":{"id":"J0NvXJUk37bU"},"source":["def extract_vgg16(img_path, model):\n","    # Buoc 1: Load anh tu file va resize sang \n","    # kich thuoc 224 x 224\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_data = image.img_to_array(img)\n","    img_data = np.expand_dims(img_data, axis=0)\n","    img_data = preprocess_input(img_data)\n","    # Buoc 2: Feed anh vao model de duoc feature\n","    feature = model.predict(img_data)\n","    feature_np = np.array(feature)\n","    feature_flat = feature_np.reshape(-1)\n","    return feature_flat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Z7NzElUMTOp"},"source":["Next, we scan all image in the data directory and extract features."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoG5VWKL4xID","executionInfo":{"status":"ok","timestamp":1623829101408,"user_tz":-420,"elapsed":8190,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"462e92d8-3f3a-4a99-d93a-9d3600128098"},"source":["paths = glob.glob(tutorial_path + '/data/image/*.jpg')\n","feats = []\n","for i, path in enumerate(paths):\n","    print('Extracting deep feature of image {}: {}'.format(i,path))\n","    # Extract features\n","    feat = extract_vgg16(path, model)\n","    #norm_feat = feat/np.sum(feat)\n","    feats.append(feat)\n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Extracting deep feature of image 0: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/beach_and_girl.jpg\n","Extracting deep feature of image 1: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/beach_and_girl2.jpg\n","Extracting deep feature of image 2: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/street_food2.jpg\n","Extracting deep feature of image 3: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/dog.jpg\n","Extracting deep feature of image 4: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/dog1.jpg\n","Extracting deep feature of image 5: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/car.jpg\n","Extracting deep feature of image 6: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/car_dog.jpg\n","Extracting deep feature of image 7: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/ntdb_01.jpg\n","Extracting deep feature of image 8: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/cho_ben_thanh_01.jpg\n","Extracting deep feature of image 9: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/cho_ben_thanh_03.jpg\n","Extracting deep feature of image 10: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/Dia-diem-du-lich-noi-tieng-o-ha-noi.jpg\n","Extracting deep feature of image 11: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/dia-diem-du-lich-gan-ha-noi-31.jpg\n","Extracting deep feature of image 12: /content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/umbrella_1517721067423_33089190_ver1.0-1.jpg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mc9irp1XMbRZ"},"source":["Check feature dimension returned from previous step."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-MPQuus5Q3E","executionInfo":{"status":"ok","timestamp":1623829105877,"user_tz":-420,"elapsed":376,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"733d42cf-e79b-409b-f228-e0e050b30eea"},"source":["feats = np.array(feats)\n","print(feats.shape)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["(13, 25088)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DuyTMjxGMjO6"},"source":["#Step 3 - Feature matching\n"]},{"cell_type":"code","metadata":{"id":"KBQF6Mry5E3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623829457154,"user_tz":-420,"elapsed":444,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"d68d0484-8d6c-4819-c66e-0241d8bfeb6b"},"source":["# Choose an image in the directory\n","index = 8\n","# matching using dot product\n","sims = np.dot(feats, feats[index,:]) # feats[index,:] --> feature query màu đỏ\n","# feats -> tập các feature màu đen trong slide\n","# giải thích tại sao L2 ko tốt bằng dot product hoặc cosine\n","\n","# Print out the result\n","print('similarity between the query and dataset: ', sims)\n","rank = np.argsort(sims)\n","print('Top 3 ranked list: ')\n","print(paths[rank[-1]])\n","print(paths[rank[-2]])\n","print(paths[rank[-3]])"],"execution_count":47,"outputs":[{"output_type":"stream","text":["similarity between the query and dataset:  [ 168302.36  250120.81  396407.56  388567.06  312034.78  263690.2\n","  444044.5   855159.25 3710655.   2369484.2   221001.42  241347.08\n","  275023.88]\n","Top 3 ranked list: \n","/content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/cho_ben_thanh_01.jpg\n","/content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/cho_ben_thanh_03.jpg\n","/content/drive/MyDrive/1. Teaching/Information Retrieval/Tutorial//data/image/ntdb_01.jpg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Io4_lZTgM0px"},"source":["To visualize the ranked list, we use HTML code. It should be skipped if you dont know web programming."]},{"cell_type":"code","metadata":{"id":"wf1SwmRiMxuT","executionInfo":{"status":"ok","timestamp":1623829409684,"user_tz":-420,"elapsed":398,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}}},"source":["from IPython import display\n","import base64\n","\n","def append_to_html(query_index, query_path, urls, scores):\n","  \"\"\"Display a text query and the top result videos and scores.\"\"\"\n","  html = ''\n","  html += '<h2>Input query: <i>{}</i> </h2><div>'.format(query_index)\n","  data_uri = base64.b64encode(open(query_path, 'rb').read()).decode('utf-8')\n","  html += '<img src=\"data:image/png;base64,{0}\" height=\"224\">'.format(data_uri)\n","  html += '<br><h2>Results:</h2><br> <div>'\n","  html += '<table><tr>'\n","  for idx, score in enumerate(scores):\n","    html += '<th>Rank #{}, Score:{:.2f}</th>'.format(idx+1, score)\n","  html += '</tr><tr>'\n","  for i, url in enumerate(urls):\n","    html += '<td>'\n","    data_uri = base64.b64encode(open(url, 'rb').read()).decode('utf-8')\n","    html += '<img src=\"data:image/png;base64,{0}\" height=\"224\">'.format(data_uri)\n","    html += '</td>'\n","  html += '</tr></table></div></div>'\n","  return html"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621,"output_embedded_package_id":"1zbW6_dj_7UK7f599FCgEU9S27UKma8gS"},"id":"vqLGVjlQNlXw","executionInfo":{"status":"ok","timestamp":1623829464715,"user_tz":-420,"elapsed":4796,"user":{"displayName":"Tiệp Nguyễn Vinh","photoUrl":"","userId":"18255185813791937206"}},"outputId":"89e0a840-5863-4fec-a001-60c2aa56ed53"},"source":["urls = []\n","scores = []\n","for i in range(len(sims)):\n","  urls.append(paths[rank[-i-1]])\n","  scores.append(sims[-i-1])\n","html = append_to_html('Image: ' + str(index), paths[index], urls, scores)\n","display.HTML(html)"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}